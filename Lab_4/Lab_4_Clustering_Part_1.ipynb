{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOD9rzcNdylw"
      },
      "source": [
        "#**Lab 4 : CLUSTERING Part 1**\n",
        "\n",
        "In this Lab you will have to write code for 2 clustering algorithms based on the mathematical theory :\n",
        "\n",
        "1. K-means Clustering\n",
        "2. Gaussian Mixture Model\n",
        "\n",
        "You will then have to use these algorithms on a pratical dataset and compare the results with the inbuilt algorithms present in scikit learn toolkit\n",
        "\n",
        "**Please use plots wherever possible to demonstrate the results**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hnxxgNcSIeqh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xf3ZwixjeIPX"
      },
      "source": [
        "# K-means Clustering\n",
        "\n",
        "K-means clustering is a type of unsupervised learning, which is used when you have unlabeled data (i.e., data without defined categories or groups). The goal of this algorithm is to find groups in the data, with the number of groups represented by the variable K. The algorithm works iteratively to assign each data point to one of K groups based on the features that are provided. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CzYI1IC2ee4T"
      },
      "source": [
        "**Step 1 : Data Generation** \n",
        "\n",
        "Generate 2D gaussian data of 4 types each having 100 points, by taking appropriate mean and varince (example: mean :(0.5 0) (5 5) (5 1) (10 1.5), variance : Identity matrix)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "mgWrF36qduKS",
        "outputId": "9ac82aaf-35b3-4fed-b062-fcd00b63c876"
      },
      "outputs": [],
      "source": [
        "# write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-muoIoZIhWOf"
      },
      "source": [
        "**Step 2 : Cluster Initialisation**\n",
        "\n",
        "Initialse K number of Clusters (Here, K=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "ndyT_mQxfNbj",
        "outputId": "74e50f81-52e2-4308-fd79-6f5031696fe3"
      },
      "outputs": [],
      "source": [
        "# write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKe2bHybhpJj"
      },
      "source": [
        "**Step 3 : Cluster assignment and re-estimation Stage**\n",
        "\n",
        "a) Using initial/estimated cluster centers (mean $\\mu_{i}$) perform cluster assignment.\n",
        "\n",
        "b) Assigned cluster for each feature vector ($X_{j}$) can be written as:\n",
        "$$arg \\min_{i} ||C_{i}-X_{j}||_{2},~1 \\leq i \\leq K,~1\\leq j \\leq N$$ \n",
        "c) Re-estimation: After cluster assignment, the mean vector is recomputed as,\n",
        "$$\\mu_{i}=\\frac{1}{N_{i}}\\sum_{j \\in i^{th} cluster}X_{j}$$\n",
        "where $N_{i}$ represents the number of datapoints in the $i^{th}$ cluster.\n",
        "\n",
        "d) Objective function (to be minimized):\n",
        "$$Error(\\mu)=\\frac{1}{N}\\sum_{i=1}^{K}\\sum_{j \\in i^{th} cluster}||C_{i}-X_{j}||_{2}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2n7UiZ29fNX9",
        "outputId": "e6a7e847-6143-4833-d68f-b3cbf8ef126c"
      },
      "outputs": [],
      "source": [
        "# write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-y4uMpaFZ1LS"
      },
      "source": [
        "**Step 4 : Performance metric**\n",
        "\n",
        "Compute Homogeneity score and Silhouette coefficient using the information given below \n",
        "\n",
        "Homogeneity score : A clustering result satisfies homogeneity if all of its clusters contain only data points which are members of a single class.\n",
        "This metric is independent of the absolute values of the labels: a permutation of the class or cluster label values wonâ€™t change the score value in any way.\n",
        "\n",
        "Silhouette coeeficient : \n",
        "\n",
        "$a(x)$ : Average distance of x to all other vectors in same cluster\n",
        "\n",
        "$b(x)$ : Average distance of x to the vectors in other clusters. Find minimum among the clusters\n",
        "\n",
        "$s(x)$ = $\\frac{b(x) - a(x)}{max(a(x),b(x))}$\n",
        "\n",
        "Silhouette coefficient (SC) : \n",
        "\n",
        "$$ SC =  \\frac{1}{N}\\sum_{i=1}^{N}s(x) $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "617h6D9fKtiG"
      },
      "outputs": [],
      "source": [
        "# write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esk87sJyfOSK"
      },
      "source": [
        "# Gaussian Mixture Models Clustering\n",
        "\n",
        "Gaussian mixture model is an unsupervised machine learning method. It summarizes a multivariate probability density function with a mixture of Gaussian probability distributions as its name suggests. It can be used for data clustering and data mining. In this lab, GMM is used for clustering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5okXWpqg1Mv"
      },
      "source": [
        "**Step 1:  Data generation**\n",
        "\n",
        "a) Follow the same steps as in K-means Clustering to generate the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Sot5t3yViNd1",
        "outputId": "4b065140-811a-4f0a-a3d5-9a2f3e39c23e"
      },
      "outputs": [],
      "source": [
        "# write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-biZlGrJiLBG"
      },
      "source": [
        "**Step 2. Initialization**\n",
        "\n",
        "a) Mean vector (randomly any from the given data points) ($\\mu_{k}$)\n",
        "\n",
        "b) Coveriance (initialize with (identity matrix)*max(data))  ($\\Sigma_{k}$)\n",
        "\n",
        "c) Weights (uniformly) ($w_{k}$), \n",
        "with constraint: $\\sum_{k=1}^{K}w_{k}=1$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XSi-h3pUiQbC"
      },
      "outputs": [],
      "source": [
        "def initialization(data,K):\n",
        "\n",
        "  # write your code here\n",
        "    \n",
        "  return theta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhx2HVQDiTfP"
      },
      "source": [
        "**Step 3: Expectation stage**\n",
        "\n",
        "$$\\gamma_{ik}=\\frac{w_{k}P(x_{i}|\\Phi_{k})}{\\sum_{k=1}^{K}w_{k}P(x_{i}|\\Phi_{k})}$$\n",
        "\n",
        "where,\n",
        "$$\\Phi_{k}=\\{\\mu_{k},\\Sigma_{k}\\}$$\n",
        "$$\\theta_{k}=\\{\\Phi_{k},w_{k}\\}$$\n",
        "$$w_{k}=\\frac{N_{k}}{N}$$\n",
        "$$N_{k}=\\sum_{i=1}^{N}\\gamma_{ik}$$\n",
        "$$P(x_{i}|\\Phi_{k})=\\frac{1}{(2 \\pi)^{d/2}|\\Sigma_{k}|^{1/2}}e^{-(x_{i}-\\mu_{k})^{T}\\Sigma_{k}^{-1}(x_{i}-\\mu_{k})}$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bVJ-vkSDiVrj"
      },
      "outputs": [],
      "source": [
        "# E-Step GMM\n",
        "from scipy.stats import multivariate_normal\n",
        "\n",
        "def E_Step_GMM(data,K,theta):\n",
        "\n",
        "    # write your code here\n",
        "\n",
        "    return responsibility"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9J7VAssiqTc"
      },
      "source": [
        "**Step 4: Maximization stage**\n",
        "\n",
        "a) $w_{k}=\\frac{N_{k}}{N}$, where  $N_{k}=\\sum_{i=1}^{N}\\gamma_{ik}$\n",
        "\n",
        "b) $\\mu_{k}=\\frac{\\sum_{i=1}^{N}\\gamma_{ik}x_{i}}{N_{k}}$\n",
        "\n",
        "c) $\\Sigma_{k}=\\frac{\\sum_{i=1}^{N}\\gamma_{ik}(x_{i}-\\mu_{k})(x_{i}-\\mu_{k})^{T}}{N_{k}}$\n",
        "\n",
        "Objective function(maximized through iteration):\n",
        "$$L(\\theta)=\\sum_{i=1}^{N}log\\sum_{k=1}^{K}w_{k}P(x_{i}|\\Phi_{k})$$ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtxZDvEciw2R"
      },
      "outputs": [],
      "source": [
        "# M-STEP GMM\n",
        "\n",
        "def M_Step_GMM(data,responsibility):\n",
        "    \n",
        "    # write your code here\n",
        "           \n",
        "    return theta, log_likelihood"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEG8BcXhi1OS"
      },
      "source": [
        "**Step 5: Final run (EM algorithm)**\n",
        "\n",
        "a) Initialization\n",
        "\n",
        "b)Iterate E-M untill $L(\\theta_{n})-L(\\theta_{n-1}) \\leq th$ \n",
        "\n",
        "c) Plot and see the cluster allocation at each iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pqs2Uutfi9_E",
        "outputId": "15739d85-3a5d-4051-b3de-2b455f9bcc6e"
      },
      "outputs": [],
      "source": [
        "log_l=[]\n",
        "Itr=50\n",
        "eps=10**(-14)  # for threshold\n",
        "clr=['r','g','b','y','k','m','c']\n",
        "mrk=['+','*','X','o','.','<','p']\n",
        "\n",
        "\n",
        "K = 4   # no. of clusters\n",
        "\n",
        "theta=initialization(data,K)\n",
        "\n",
        "for n in range(Itr):\n",
        "\n",
        "  responsibility=E_Step_GMM(data,K,theta)\n",
        "\n",
        "  cluster_label=np.argmax(responsibility,axis=1) #Label Points\n",
        "\n",
        "  theta,log_likhd=M_Step_GMM(data,responsibility)\n",
        "\n",
        "  log_l.append(log_likhd)\n",
        "\n",
        "  plt.figure()\n",
        "  for l in range(K):\n",
        "    id=np.where(cluster_label==l)\n",
        "    plt.plot(data[id,0],data[id,1],'.',color=clr[l],marker=mrk[l])\n",
        "  Cents=theta[0].T\n",
        "  plt.plot(Cents[:,0],Cents[:,1],'X',color='k')\n",
        "  plt.title('Iteration= %d' % (n))\n",
        "\n",
        "  if n>2:\n",
        "    if abs(log_l[n]-log_l[n-1])<eps:\n",
        "      break\n",
        "\n",
        "\n",
        "plt.figure()  \n",
        "plt.plot(log_l)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5YqgUpB7aToE"
      },
      "source": [
        "**Step 6 : Performance metric**\n",
        "\n",
        "Compute Homogeneity score and Silhouette coefficient using the information given below \n",
        "\n",
        "Homogeneity score : A clustering result satisfies homogeneity if all of its clusters contain only data points which are members of a single class.\n",
        "This metric is independent of the absolute values of the labels: a permutation of the class or cluster label values wonâ€™t change the score value in any way.\n",
        "\n",
        "Silhouette coeeficient : \n",
        "\n",
        "$a(x)$ : Average distance of x to all other vectors in same cluster\n",
        "\n",
        "$b(x)$ : Average distance of x to the vectors in other clusters. Find minimum among the clusters\n",
        "\n",
        "$s(x)$ = $\\frac{b(x) - a(x)}{max(a(x),b(x))}$\n",
        "\n",
        "Silhouette coefficient (SC) : \n",
        "\n",
        "$$ SC =  \\frac{1}{N}\\sum_{i=1}^{N}s(x) $$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rjV5eA3wLz8h"
      },
      "outputs": [],
      "source": [
        "# write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYp2zyOatoqN"
      },
      "source": [
        "# GMM v/s K-means"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7WtglUXts88"
      },
      "source": [
        "(a) Generate Data to show shortcomings of Kmeans and advantage of GMM over it\n",
        "\n",
        "(b) Perform GMM on the same data and justify how it is better than K-means in that particular case\n",
        "\n",
        "(c) Verify the same using performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIhmji-L7LdD"
      },
      "outputs": [],
      "source": [
        "# write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gU6Wqv8iI81r"
      },
      "source": [
        "# Practical Use Case : K-means Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxY5zdERQZWi"
      },
      "source": [
        "For this exercise we will be using the **IRIS FLOWER DATASET** and explore how K-means clustering is performing\n",
        "\n",
        "**IRIS Dataset** consists of 50 samples from each of the three species of Iris flower (Iris Setosa, Iris Viriginca and Iris Versicolor)\n",
        "\n",
        "Four features were measured from each sample : Length of Sepals, Width of sepals, Length of Petals, Width of Sepals all in centimeters. Based on the combinations of these 4 features each flower was categorized into one of the 3 species\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mi-0SY_ESBC1"
      },
      "source": [
        "**Steps :** \n",
        "\n",
        "(a) Convert the given iris.csv file into a Pandas Dataframe, then extract both feature vector and target vector\n",
        "\n",
        "(b) Perform analysis of Dataset, Plot the following features : (Sepal Length vs Sepal Width), (Petal Length vs Petal Width)\n",
        "\n",
        "\n",
        "(c) Next group the data points into 3 clusters using the above K-means Clustering algorithm and compare the performance against the true labels obtained by the target vector, Also explain the results using a Confusion matrix\n",
        "\n",
        "(d) Next use scikit learn tool to perform K-means Clustering and compare the performance against the true labels obtained by the target vector, Also explain the results using a Confusion matrix\n",
        "\n",
        "(e) Vary the Number of Clusters (K) and run K-means algorithm from 1-10 and find the optimal number of clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkT1mxF4R469"
      },
      "outputs": [],
      "source": [
        "## write your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fupocaVab77r"
      },
      "source": [
        "# Practical Use Case : GMM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqE8h5CRuuC0"
      },
      "source": [
        "**Steps :** \n",
        "\n",
        "(a) Convert the given iris.csv file into a Pandas Dataframe, then extract both feature vector and target vector\n",
        "\n",
        "(b) Next group the data points into 3 clusters using the above GMM Clustering algorithm and compare the performance against the true labels obtained by the target vector, Also explain the results using a Confusion matrix\n",
        "\n",
        "(c) Next use scikit learn tool to perform GMM Clustering and compare the performance against the true labels obtained by the target vector, Also explain the results using a Confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rq3PtvGTu3Tp"
      },
      "outputs": [],
      "source": [
        "# write your code here"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "IOD9rzcNdylw"
      ],
      "name": "Lab_4_Clustering Part_1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
