{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zZDMbDP0uJN0"
   },
   "source": [
    "# **LAB 10 : Hidden Markov Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "MKFudLjzt_K5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "64j_rFZeF57i"
   },
   "source": [
    "Please refer to the following [article](http://www.adeveloperdiary.com/data-science/machine-learning/introduction-to-hidden-markov-model/) to understand Hidden Markov Model\n",
    "\n",
    "Here we will be dealing with 3 major problems : \n",
    "  \n",
    "  1. Evaluation Problem\n",
    "  2. Learning Problem\n",
    "  3. Decoding Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wEasU5TNGNbE"
   },
   "source": [
    "1. Evaluation Problem : Implementation of Forward and Backward Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vjUe9joAGXvC",
    "outputId": "0a1ef95b-9653-4518-adbc-d288b6343da5"
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data_python.csv') ## Read the data, change the path accordingly\n",
    "\n",
    "V = data['Visible'].values\n",
    "\n",
    "# Transition Probabilities\n",
    "a = np.array(((0.54, 0.46), (0.49, 0.51)))\n",
    "\n",
    "# Emission Probabilities\n",
    "b = np.array(((0.16, 0.26, 0.58), (0.25, 0.28, 0.47)))\n",
    "\n",
    "# Equal Probabilities for the initial distribution\n",
    "initial_distribution = np.array((0.5, 0.5))\n",
    "\n",
    "\n",
    "def forward(V, a, b, initial_distribution):\n",
    "    alpha = np.zeros((V.shape[0], a.shape[0]))\n",
    "    \n",
    "    ## Write your code here\n",
    "    alpha[0, :] = initial_distribution * b[:, V[0]]\n",
    " \n",
    "    for t in range(1, V.shape[0]):\n",
    "        for j in range(a.shape[0]):\n",
    "            alpha[t, j] = alpha[t - 1].dot(a[:, j]) * b[j, V[t]]\n",
    " \n",
    "    return alpha\n",
    "\n",
    "\n",
    "alpha = forward(V, a, b, initial_distribution)\n",
    "\n",
    "\n",
    "def backward(V, a, b):\n",
    "    beta = np.zeros((V.shape[0], a.shape[0]))\n",
    "\n",
    "    ## Write your code here\n",
    "    beta[V.shape[0] - 1] = np.ones((a.shape[0]))\n",
    " \n",
    "    # Loop in backward way from T-1 to\n",
    "    # Due to python indexing the actual loop will be T-2 to 0\n",
    "    for t in range(V.shape[0] - 2, -1, -1):\n",
    "        for j in range(a.shape[0]):\n",
    "            beta[t, j] = (beta[t + 1] * b[:, V[t + 1]]).dot(a[j, :])\n",
    " \n",
    "    return beta\n",
    "\n",
    "\n",
    "beta = backward(V, a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Iyc4mIlGzPk"
   },
   "source": [
    "2. Learning Problem : Implementation of Baum Welch Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H6eaCtNEG3FQ",
    "outputId": "143855ca-81f4-4bfb-97f9-5a40596c15eb"
   },
   "outputs": [],
   "source": [
    "def baum_welch(V, a, b, initial_distribution, n_iter=100):\n",
    "    M = a.shape[0]\n",
    "    T = len(V)\n",
    " \n",
    "    for n in range(n_iter):\n",
    "        alpha = forward(V, a, b, initial_distribution)\n",
    "        beta = backward(V, a, b)\n",
    " \n",
    "        xi = np.zeros((M, M, T - 1))\n",
    "        for t in range(T - 1):\n",
    "            denominator = np.dot(np.dot(alpha[t, :].T, a) * b[:, V[t + 1]].T, beta[t + 1, :])\n",
    "            for i in range(M):\n",
    "                numerator = alpha[t, i] * a[i, :] * b[:, V[t + 1]].T * beta[t + 1, :].T\n",
    "                xi[i, :, t] = numerator / denominator\n",
    " \n",
    "        gamma = np.sum(xi, axis=1)\n",
    "        a = np.sum(xi, 2) / np.sum(gamma, axis=1).reshape((-1, 1))\n",
    " \n",
    "        # Add additional T'th element in gamma\n",
    "        gamma = np.hstack((gamma, np.sum(xi[:, :, T - 2], axis=0).reshape((-1, 1))))\n",
    " \n",
    "        K = b.shape[1]\n",
    "        denominator = np.sum(gamma, axis=1)\n",
    "        for l in range(K):\n",
    "            b[:, l] = np.sum(gamma[:, V == l], axis=1)\n",
    " \n",
    "        b = np.divide(b, denominator.reshape((-1, 1)))\n",
    "\n",
    "    return (a,b)\n",
    "\n",
    "data = pd.read_csv('data_python.csv')\n",
    "\n",
    "V = data['Visible'].values\n",
    "\n",
    "# Transition Probabilities\n",
    "a = np.ones((2, 2))\n",
    "a = a / np.sum(a, axis=1)\n",
    "\n",
    "# Emission Probabilities\n",
    "b = np.array(((1, 3, 5), (2, 4, 6)))\n",
    "b = b / np.sum(b, axis=1).reshape((-1, 1))\n",
    "\n",
    "# Equal Probabilities for the initial distribution\n",
    "initial_distribution = np.array((0.5, 0.5))\n",
    "\n",
    "a,b = baum_welch(V, a, b, initial_distribution, n_iter=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A40-TPXZHTHE"
   },
   "source": [
    "3. Decoding Problem : Implementation of Viterbi Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nBG74dknHYgM",
    "outputId": "1ac04c53-fea0-4047-aae0-768c6c6e0780"
   },
   "outputs": [],
   "source": [
    "def viterbi(V, a, b, initial_distribution):\n",
    "    T = V.shape[0]\n",
    "    M = a.shape[0]\n",
    " \n",
    "    omega = np.zeros((T, M))\n",
    "    omega[0, :] = np.log(initial_distribution * b[:, V[0]])\n",
    " \n",
    "    prev = np.zeros((T - 1, M))\n",
    " \n",
    "    for t in range(1, T):\n",
    "        for j in range(M):\n",
    "            # Same as Forward Probability\n",
    "            probability = omega[t - 1] + np.log(a[:, j]) + np.log(b[j, V[t]])\n",
    " \n",
    "            # This is our most probable state given previous state at time t (1)\n",
    "            prev[t - 1, j] = np.argmax(probability)\n",
    " \n",
    "            # This is the probability of the most probable state (2)\n",
    "            omega[t, j] = np.max(probability)\n",
    " \n",
    "    # Path Array\n",
    "    S = np.zeros(T)\n",
    " \n",
    "    # Find the most probable last hidden state\n",
    "    last_state = np.argmax(omega[T - 1, :])\n",
    " \n",
    "    S[0] = last_state\n",
    " \n",
    "    backtrack_index = 1\n",
    "    for i in range(T - 2, -1, -1):\n",
    "        S[backtrack_index] = prev[i, int(last_state)]\n",
    "        last_state = prev[i, int(last_state)]\n",
    "        backtrack_index += 1\n",
    " \n",
    "    # Flip the path array since we were backtracking\n",
    "    S = np.flip(S, axis=0)\n",
    " \n",
    "    # Convert numeric values to actual hidden states\n",
    "    result = []\n",
    "    for s in S:\n",
    "        if s == 0:\n",
    "            result.append(\"A\")\n",
    "        else:\n",
    "            result.append(\"B\")\n",
    "  ## Write your code here\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "data = pd.read_csv('data_python.csv')\n",
    "\n",
    "V = data['Visible'].values\n",
    "\n",
    "# Transition Probabilities\n",
    "a = np.ones((2, 2))\n",
    "a = a / np.sum(a, axis=1)\n",
    "\n",
    "# Emission Probabilities\n",
    "b = np.array(((1, 3, 5), (2, 4, 6)))\n",
    "b = b / np.sum(b, axis=1).reshape((-1, 1))\n",
    "\n",
    "# Equal Probabilities for the initial distribution\n",
    "initial_distribution = np.array((0.5, 0.5))\n",
    "\n",
    "a, b = baum_welch(V, a, b, initial_distribution, n_iter=100)\n",
    "\n",
    "result = viterbi(V, a, b, initial_distribution)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6wTG6SkvKOHl"
   },
   "source": [
    "4. Use the built-in **hmmlearn** package to fit the data and generate the result using the decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "R1iy8tj4KrwF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting hmmlearn==0.2.7\n",
      "  Downloading hmmlearn-0.2.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (129 kB)\n",
      "\u001b[K     |████████████████████████████████| 129 kB 1.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: scipy>=0.19 in /home/abhishekj/anaconda3/lib/python3.9/site-packages (from hmmlearn==0.2.7) (1.7.3)\n",
      "Requirement already satisfied: numpy>=1.10 in /home/abhishekj/anaconda3/lib/python3.9/site-packages (from hmmlearn==0.2.7) (1.21.5)\n",
      "Requirement already satisfied: scikit-learn>=0.16 in /home/abhishekj/anaconda3/lib/python3.9/site-packages (from hmmlearn==0.2.7) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/abhishekj/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.16->hmmlearn==0.2.7) (2.2.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /home/abhishekj/anaconda3/lib/python3.9/site-packages (from scikit-learn>=0.16->hmmlearn==0.2.7) (1.1.0)\n",
      "Installing collected packages: hmmlearn\n",
      "Successfully installed hmmlearn-0.2.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install hmmlearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Pw-zo9opLLlh"
   },
   "outputs": [],
   "source": [
    "## Write your code here\n",
    "from hmmlearn import hmm\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "data = pd.read_csv('data_python.csv')\n",
    "\n",
    "V = data['Visible'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500,)\n",
      "(1, 500)\n"
     ]
    }
   ],
   "source": [
    "print(V.shape)\n",
    "V_reshaped = np.array(V.reshape(-1,1)).T\n",
    "print(V_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['B', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'B', 'A', 'B', 'B', 'B', 'B', 'A', 'B', 'A', 'B', 'B', 'B', 'B', 'A', 'B', 'B', 'B', 'B', 'A', 'B', 'B', 'A', 'B', 'B', 'B', 'A', 'B', 'B', 'B', 'A', 'B', 'B', 'B', 'A', 'B', 'A', 'B', 'B', 'A', 'B', 'A', 'A', 'A', 'B', 'A', 'B', 'A', 'B', 'B', 'B', 'A', 'A', 'B', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'A', 'B', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'A', 'A', 'B', 'A', 'B', 'B', 'B', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'B', 'A', 'B', 'B', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'B', 'A', 'B', 'B', 'B', 'B', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'A', 'B', 'B', 'A', 'A', 'B', 'A', 'A', 'A', 'B', 'B', 'B', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'A', 'A', 'B', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'B', 'A', 'B', 'B', 'B', 'A', 'B', 'B', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'A', 'B', 'A', 'B', 'B', 'A', 'B', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'A', 'A', 'B', 'B', 'A', 'A', 'A', 'B', 'B', 'B', 'A', 'A', 'B', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'A', 'A', 'B', 'A', 'B', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'A', 'B', 'B', 'B', 'A', 'A', 'B', 'B', 'A', 'B', 'B', 'A', 'B', 'B', 'B', 'B', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'A', 'B', 'A', 'B', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'B', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'B', 'A', 'B', 'B', 'A', 'B', 'A', 'B', 'A', 'B', 'B', 'A', 'A', 'B', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'B', 'B', 'A', 'B', 'A', 'A', 'A', 'A', 'A', 'A', 'A', 'B', 'A', 'A', 'A', 'B', 'A', 'A', 'B', 'A', 'A', 'A', 'A', 'B', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'B', 'B', 'B', 'A', 'B', 'B', 'A', 'A', 'A', 'B', 'B', 'B', 'B', 'A', 'B', 'A', 'A', 'A', 'B', 'A', 'B', 'A', 'A', 'B', 'B', 'A', 'B', 'B', 'B', 'B', 'B', 'B', 'B', 'A', 'B', 'B', 'B', 'A', 'B', 'A', 'A', 'B', 'B', 'B', 'A', 'B', 'B', 'A', 'A', 'B', 'A']\n"
     ]
    }
   ],
   "source": [
    "model = hmm.MultinomialHMM(n_components=2)\n",
    "\n",
    "model.startprob_ = np.array([0.5, 0.5])\n",
    "model.transmat_ = np.array([[0.5, 0.5],\n",
    "                            [0.5, 0.5]])\n",
    "model.emissionprob_ = np.array([[0.11111111, 0.33333333, 0.55555556],\n",
    "                                [0.16666667, 0.33333333 ,0.5]])\n",
    "\n",
    "logprob, sequence = model.decode(V_reshaped)\n",
    "out = []\n",
    "for i in sequence:\n",
    "  if i == 1:\n",
    "    i = \"B\"\n",
    "  else:\n",
    "    i = \"A\"\n",
    "  out.append(i)\n",
    "print(out)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Lab_11_Hidden_Markov_Model.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
